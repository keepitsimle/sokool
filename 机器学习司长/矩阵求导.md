符号表示:

	标量 :普通的小写字母或者希腊字母,如$t$,$\alpha$
	
	向量用粗体小写字母或者粗体希腊字母.如**x**,其元素为$x_i$,小写x未加粗.向量默认为列向量.其转置为**$x^T$**
	
	矩阵使用$A$表示.元素为$a_{ij}$



**约定:**

1. **矩阵/向量值函数对实数的导数:**

2. 

   1. 结果与函数值同型,每个元素的导数为函数值对应的分量对自变量$x$求导
   2. 如果函数$F:R \to R^{m*n}$,则$\partial F /\partial x$ 也是一个$m*n$矩阵,而且$({\partial F /\partial x} )_{ij}$= ${\partial {f_{ij}}} /{\partial x}$,或者记成$\triangledown_x F$,$F_x^{'}$
   3. 由2可以推导出$F$是向量,包括行向量/列向量的情况.

3. **实数函数对矩阵/向量的导数**

   1. 结果同型,每个元素是$f$对自变量的相应分量求导
   2. 若函数$f:R^{m*n} \to R$,则${\partial f}/{\part X}$也是一个$m*n$的矩阵.且$({\part f}/{\part X})_{ij} = {\part f}/{\part x_{ij}}$.记成$\triangledown_ x f$

4. **向量值函数对向量的导数(雅可比矩阵)**

   1. 若函数$f:R^n\to R^m$,则**$\part \mathbf{f} /\part \mathbf{x}$**,==这里的$f$,$x$都是黑体,因为是向量.==是一个$m*n$的矩阵.且$({{\part \mathbf{f} }/{\part \mathbf x}})_{ij} = {\part f_i}/{\part x_j}$,标为$\triangledown_ x f$ ,同样是大写的.
   2. 这里不区分向量$\mathbf x \in R^n$ 到 $\mathbf f \in R^m$的雅可比矩阵时,不去区分$\mathbf x$或者$\mathbf f$是行向量还是列向量.统一使用$\triangledown _x \mathbf f $表示.维度为m-by-n.
   3. 有一点需要特别注意:如果$\mathbf f$退化为标量$f$,则$\mathbf x$到$f$的雅可比矩阵是一个行向量.是梯度(列向量)的转置.即${\part \mathbf f}/{\part \mathbf x} = ({\part f}/{\part \mathbf x})^T  $,左边的$\mathbf f$加粗,是将它看成向量,右边$f$为非加粗的字体,表示实值函数$f$对向量$\mathbf x$的导数
   4. 
   5. 
   6. 
   7. 

5. 关于$\triangledown $劈形算子的说明

   1. 在求导变量明确的情况下,可使用$\triangledown f$
   2. 对于一个实值函数$f:\mathbf R^{m} \to \mathbf R$,梯度为$\triangledown f = {\part f}/{\part \mathbf x}$,记为gradf,是一个$m$维的向量.Hessian矩阵为$\triangledown^2 f$,其中$(\triangledown^2 f)_{ij} = {\part^2 f}/{\part x_i \part x_j}$,是一个$m*m$矩阵.

6. 向量求导的链式法则

   1. 雅可比矩阵的传递性:$\mathbf u \to \mathbf v \to \mathbf w$,则$\frac {\part \mathbf w} {\part \mathbf u} = \frac {\part \mathbf w} {\part \mathbf v} \frac {\part \mathbf v} {\part \mathbf u}  $,这里的$\mathbf w,\mathbf v,\mathbf u $都是向量.

      1. 证明:求解$\frac {\part w_i}{\part u_j} = \sum_k (\frac {\part w_i}{\part u_k})(\frac {\part w_k}{\part u_j})$,即$\frac {\part \mathbf w} {\part \mathbf u}$的$(i,j)$的元等于$\frac {\part \mathbf w} {\part \mathbf u}$的第$i$行与矩阵$\frac {\part \mathbf w} {\part \mathbf u}$的第$j$列的内积.这是矩阵乘法的定义.
      2. ==将两项乘积转为内积或者矩阵的相乘是很常用的技巧.==

   2. 若中间变量都是向量,而最后的结果是一个实值函数,如$\mathbf x \to \mathbf v \to \mathbf u \to f $,根据$\mathbf f$退化成为$f$时,有$\frac {\part \mathbf f} {\part \mathbf x} = \frac {\part f} {\part \mathbf x^T} $,  $\frac {\part \mathbf f} {\part \mathbf u} = \frac {\part f} {\part \mathbf u^T} $,可以得到链式公式:$ \frac {\part f} {\part \mathbf x^T} =  \frac {\part f} {\part \mathbf u^T} \frac {\part \mathbf u} {\part \mathbf v} \frac {\part \mathbf v} {\part \mathbf x}$,向量对实值函数导数最好搞成行向量.将$\frac {\part f}{\part \mathbf x^T}$和$\frac {\part f}{\part \mathbf u^T}$都视为行向量.

   3. 如果要将导数视为列向量,只需要将结果两边同时转置即可.

      1. 如$y=f(\mathbf u),\mathbf u = g(\mathbf x)$,则$\frac {\part f}{\part \mathbf x} = (\frac {\part \mathbf u}{\part \mathbf x} )^T \frac {\part f}{\part \mathbf u} $,或者写为$\triangledown_x f = (\triangledown_x \mathbf u)^T \triangledown_u f$,看看矩阵的维度行向量乘矩阵结果还是行向量.
      2. 特例:如存在关系$\mathbf x \to \mathbf u \to f$,$\mathbf u$和$ \mathbf x$维度相同,而且$u_i$只由$x_i$与其他的变量无关,得出,则$\frac {\part \mathbf u} {\part \mathbf x}$是对角阵哦,因此公式简化为:$\frac {\part f}{\part \mathbf x} = vec (  \frac{\part \mathbf u}{\part \mathbf x} ) \odot \frac {\part f}{\part \mathbf u} $,$vec(\mathbf D)$是对角线上元素组成的列向量.$\odot$表示两个向量逐元素相乘.

   4. 记住:结果是一堆雅可比矩阵的乘积.**==相乘的顺序根据矩阵维度相容的原则即可==**

   5. 

      - 	

7. 实值函数对向量求导:

   1. 基本的雅可比矩阵:
      1. $\triangledown A \mathbf x = A$ 
      2.  $\triangledown  \mathbf x = \mathbf I$
   2. 向量内积的求导法则
      1. 内积是数量,相当于实数对向量求导,结果是与自变量同型的向量.
      2. $\triangledown (\mathbf a^T \mathbf x) = \mathbf a$ 
         1. 因为$\frac {\part {\mathbf a^T \mathbf x}}{\part x_i} = \frac {\part \sum_j{a_jx_j}}{\part x_i} = \frac {\part a_ix_i}{\part x_i} = a_i​$
         2. $\triangledown {\| x\|}_2^2 = \triangledown(\mathbf x^T \mathbf x) = 2\mathbf x$,因为$\frac {\part {\|\mathbf x\|}^2_2}{\part x_i} = \frac {\part \sum_j x_j^2}{\part x_i} = \frac {\part x_i^2}{\part x_i} = 2x_i$,**==*所有的求解都是先得到矩阵的维度,接着算矩阵里面元素的值.==***
         3. $\triangledown (\mathbf x^T \mathbf A \mathbf x) = (\mathbf A + \mathbf A^T) \mathbf x$
         4. 
   3. 
   4. 
   5. 
   6. 
   7. 
   8. 
   9. 
   10. 
   11. 
   12. 
   13. 1. 
       2.  
       3. 

8. 

9. 

10. 

11. 

12. 

13. 

14. 

15. 

  ​     

  ​     

  ​     